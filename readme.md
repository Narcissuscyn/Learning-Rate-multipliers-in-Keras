keras2.2.0
差分学习率

仿照Kunal Saluja
实现了NAdam,Adam,RMSProp为不同层设置不同学习率
原文链接
https://ksaluja15.github.io/Learning-Rate-Multipliers-in-Keras/


